{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning 기초  \n",
    "\n",
    "![](./main.jpg)  \n",
    "이제 본격적으로! 머신러닝에 대해 공부해볼 겁니다. 아마 많은 분들이 이 컨텐츠에 대해 관심을 가지고 스터디를 신청하셨을 거 같아요 ㅎㅎ 하지만 데이터에 대해 익숙해지지 않은 상태로 바로 머신러닝과 인공지능에 들어가면 그 흐름을 이해하지도 못한 채, 정말 의미 없이 여러분의 시간을 날려버릴 가능성이 매우 높습니다. 비유를 하자면.. 사칙연산을 배우지도 않고 미분부터 하는 느낌정도? \n",
    "  \n",
    "아무튼! 여기까지 배운 내용들을 잘 해결하셨다면, 이제부터 하는 내용은 **\"코드적으로는\"** 그렇게 어렵지 않을 거예요! 지금부터는 코드를 연습한다는 느낌보다는 `개념의 흐름을 더 중요하게` 생각하시고 공부하시는 게 얻어가는 게 더 많을 겁니다. \n",
    "  \n",
    "나중에 짜게 되실 복잡한 딥러닝 코드들도, 결국 이러한 흐름을 코드로 표현한 것에 불과하니까요!  \n",
    "  \n",
    "머신러닝 컨텐츠는 3주에 걸쳐 진행됩니다. 그 중 첫 주차인 오늘은, 머신러닝의 간단한 흐름과 그 과정들을 대표적인 도구인 `sklearn`을 통해 배워볼 거예요!  \n",
    "  \n",
    "`sklearn`을 통해 가장 간단한 데이터셋에 대해 분류 작업을 수행해보고, 간단하게 흐름 정도만 파악하겠습니다. 학습에 있어서 데이터의 어떤 특성이 요구되는지, 그런 특성들을 어떻게 만들 수 있는지는 다음주차인 `지도학습` 시간에 다뤄보도록 할게요! \n",
    "\n",
    "\n",
    "<br>\n",
    "\n",
    "--- \n",
    "**알림**\n",
    "- 본 컨텐츠는 강의 형식이 아닌, 스스로 공부하시는 분들을 위한 일종의 문제집 입니다.\n",
    "- 데이터라는 큰 바다에서 여러분이 쓸 데 없는 시간 낭비 없이 바로바로 핵심을 배우실 수 있도록 커리큘럼을 짜봤습니다.\n",
    "- 이 컨텐츠의 문제들만 해결한다고 실력이 오르지 않습니다. 본 컨텐츠의 목적은 문제를 해결하는 과정에서 발생하는 고민과 질문을 통한 실력 향상입니다. \n",
    "- 문제에서 절대 떠먹여주지 않습니다. 물고기를 잡아주는 것이 아닌, 물고기를 잡는 방법을 여러분이 이 컨텐츠를 통해 알아가셨으면 합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 간단한 분류 프로젝트 해보기\n",
    "머신러닝은 별 게 아닙니다. 모여진 데이터들에서 정해진 패턴을 파악하는 걸 있어보이게 머신러닝이라고 이름을 붙인 것뿐입니다.  \n",
    "  \n",
    "예를 들어, 우리가 다뤘던 데이터인 펭귄데이터셋도 생각해보면 그런 느낌이었죠.  \n",
    "> 부리의 길이가 x, 두께는 y, 몸무게는 z, 사는 지역은 k 인 펭귄의 종은 A   \n",
    "\n",
    "이런 식의 어떤 대상(Target)과 대상이이 가지는 특징(Feature)들의 관계를 파악하는 게 바로 머신러닝입니다.\n",
    "  \n",
    "> 내가 예전에 학습한 데이터에 의하면... 부리의 길이가 x'고 두께는 y'고 몸무게는 z', 사는 지역은 k' 이니까.... 이 펭귄의 종은 A겠군!  \n",
    "\n",
    " 라고 할 수 있도록 우리는 기계를 학습시키는 게 우리의 목표인 것이죠.  \n",
    "  \n",
    "그래서 **Machine Learning**이기도 하구요. 그럼, 기계는 어떻게 학습시킬 수 있을까요? 한번 가장 기초적인 과정을 따라가봅시다!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1-1 데이터 불러오기\n",
    "위에서 말씀 드렸다 싶이, 머신러닝은 데이터가 가지는 특징(Feature)과 그래서 그 데이터가 뭔지(Target) 사이의 패턴을 파악하는 일입니다.  \n",
    "  \n",
    "이번 시간에는 간단하게, 유방암의 여부를 예측해보는 Task를 해볼 겁니다.   \n",
    "아래 코드를 실행시켜, 유방암 데이터를 받아주세요  \n",
    "  \n",
    "<br>\n",
    "\n",
    "```python\n",
    "X, y = load_breast_cancer(return_X_y=True, as_frame=True)\n",
    "\n",
    "dataset = pd.concat([X, y], axis=1)\n",
    "dataset\n",
    "```\n",
    "  \n",
    "<br>\n",
    "  \n",
    "데이터를 받아주신 뒤, 이 데이터의 Feature는 어떤지, Label은 어떤지 설명해주세요.  \n",
    "다시 말해, 이 데이터는 어떤 목표를 가지고 구축된 데이터인지 말씀해주세요!\n",
    "\n",
    "_예시_  \n",
    "![](./1-1answer.png)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1-2 train_test_split\n",
    "\n",
    "머신러닝을 훈련시킬 때는 머신러닝이 패턴을 학습할 `학습데이터`와 모델의 성능을 학습과정에서 평가하기 위한 `검증데이터`, 마지막으로 최종적으로 실전 투입에서의 성능을 평가하기 위한 `테스트데이터`가 필요합니다.\n",
    "  \n",
    "쉽게 비유하면, 수능이라는 점수를 잘 내기 위해서 평소에 1월 ~ 8월 모의고사로 공부를 하고, 9월 모의고사로 \"아 대충 이정도 나오겠구나~\"로 생각하죠?  \n",
    "여기서 1월에서 8월까지의 모의고사를 `학습데이터`라고 할 수 있고, 실전은 아니지만 실전 상황을 가정하고 우리의 실력을 확인해보기 위해 사용한 9월 모의고사 성적을 `검증데이터`, 그리고 수능을 `테스트데이터`라고 할 수 있습니다.\n",
    "  \n",
    "실전에선, 데이터 한 뭉텅이만 있고, 우리는 그 데이터에 대해 학습시킨 다음, 미래에 들어올 미지의 데이터를 예측해야합니다.  \n",
    "즉, 환자 500명의 데이터만을 가지고, 앞으로 들어올 환자(기존의 500명에는 포함 안 되어 있는 새로운 환자)의 데이터만을 가지고 유방암이 걸렸는지 안 걸렸는지 예측을 해내야 한다는 것이죠. \n",
    "  \n",
    "그래서!! 일단 가지고 있는 데이터를 **분리**시켜야 합니다.  \n",
    "위에서 말했던 그대로, 이 모델이 어느 정도의 성능이 될 지 미리 알아둘 필요가 있기 때문이죠.  \n",
    "  \n",
    "`sklearn`의 `train_test_split`을 이용하면, 쉽게 처리할 수 있습니다.\n",
    "  \n",
    "아래 예시 코드의 빈 칸에 들어갈 함수를 입력하고, 학습 데이터와 검증 데이터를 나눠주세요!  \n",
    "  \n",
    "**단, 검증데이터의 비율은 0.2, random_state=42로 고정시켜주세요.**\n",
    "```python\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_val, y_train, y_val = \"\"\"HERE YOUR CODE\"\"\"\n",
    "print(f\"Shape of X_train: {X_train.shape}\")\n",
    "print(f\"Shape of y_train: {y_train.shape}\")\n",
    "print(f\"Shape of X_val: {X_test.shape}\")\n",
    "print(f\"Shape of y_val: {y_test.shape}\")\n",
    "```\n",
    "  \n",
    "__예시__  \n",
    "![](./1-2answer.png)\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 간단한 O, X퀴즈\n",
    "- 위에서 분리해낸 X_val과 y_val은 학습 과정에 사용되어, 모델의 패턴 학습에 활용된다 (O, X)  \n",
    "🙅‍♀️ 땡!!!! 검증 데이터셋은 말 그대로 모델의 성능을 실전에 투입되기 전에 테스트해보기 위한 용도입니다. 즉, 실전을 가정하는 데이터셋이라는 것이죠. 우리가 9월 모의고사로 실력을 테스트해보려고 하는데 9월 모의고사 문제와 답안지를 미리 알고 있으면 안 된다는 얘기입니다. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Preprocessing 전처리\n",
    "데이터셋 분리에 성공했다면, 이제 전처리를 해주어야 합니다.  \n",
    "전처리를 모델의 성능을 가르는 가장 큰 요소로, 사실 어떤 모델을 썼냐~ 세부 설정은 뭐로 했냐~ 이런 거보다 데이터 전처리를 바꾸는 게 성능을 가장 크게 바꾼답니다.  \n",
    "  \n",
    "\n",
    "> **\"Garbage in, Garbage out!!\"**  \n",
    "\n",
    "Data Driven 사고에 대해서 조금 더 알고 싶으시다면, [여기](https://www.techopedia.com/whats-the-difference-between-model-driven-ai-and-data-driven-ai/7/34776)에서 한번 쭉 읽어보시는 것도 흥미진진 하실거예요 ㅎㅎ\n",
    "  \n",
    "그런 만큼, 전처리는 모델의 전체적인 과정에 있어 가장 오랜 시간을 들여야 하는 파트입니다.  \n",
    "  \n",
    "쉽게 비유를 하면, 우리가 여자친구나 남자친구에게 크리스마스에 파스타를 만들어주려고 한다고 해봅시다.  \n",
    "그럼, 장을 보고~ 재료 정리하고~ 재료 다듬고~ 요리하고~ 서빙하고~ 이 과정을 거치는데, 실제로 어디에서 가~~장 시간이 많이 쇼요될까요?  \n",
    "  \n",
    "맞아요 사실 장을보고 재료를 다듬는 과정까지가 제일 오래 걸린답니다. 실제로 요리하는 시간은 생각보다 오래 걸리지 않거든요 ㅎㅎ   \n",
    "  \n",
    "우리가 모델링 하는 걸 요리로 비유했을 때, **재료를 다듬는 과정까지를 전처리**라고 할 수 있습니다. 하지만 동시에 **가장 중요한 과정**이라고 할 수 있습니다.\n",
    "사실 4주에 걸쳐 데이터를 핸들링하는 방법에 대해 배운 이유는, 바로 이 전처리에 걸리는 시간을 좀 줄이기 위해서도 없지 않아 있어요 ㅎㅎ..  \n",
    "  \n",
    "가장 오래 걸리고 이런 저런 생각을 많이 해야하는 파트지만, 우리는 튜토리얼이니까 조금 간단하게 `결측치 제거`와 `Scaling`만 보고 넘어가보도록 할게요."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2-1 null값 삭제\n",
    "데이터를 학습하는 데에 있어서 null값(결측치)는 도움이 되지 않습니다. 오히려 학습을 방해하거나 혼동을 줄 수 있죠.  \n",
    "결측치를 다루는 방법은 여러가지가 있습니다.  \n",
    "  \n",
    "> 1. 삭제하기\n",
    "> 2. 다른 값으로 대체하기  \n",
    ">     2-1. 통계값(평균값, 최빈값, 중앙값..)  \n",
    ">     2-2. EDA를 통해 알아낸 사실로 대체하기 (필사할 때 아셨죠?)  \n",
    "  \n",
    "이 외에도 다양한 방법이 있지만 일단 우리는 여기서 가장 간단한 방법인 `삭제하기` 로 실습해보도록  \n",
    "  \n",
    "**우리가 사용하는 데이터에는 결측치가 없기 때문에, 일단 나름대로 Data Frame을 생성해보고, 결측치를 제거하는 코드를 실습해볼게요!**\n",
    "\n",
    "<br>\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.DataFrame(np.random.randn(100, 5), columns=[\"A\",\"B\",\"C\",\"D\",\"E\"])\n",
    "\n",
    "for _ in range(10):\n",
    "    row_idx = np.random.choice(df.index)\n",
    "    col_idx = np.random.choice(df.columns)\n",
    "    df.loc[row_idx, col_idx] = np.nan\n",
    "\n",
    "print(f\"🔎 # of NaN Values :\\n {df.isnull().sum()}\")\n",
    "print(f\"Shape of Data Frame : {df.shape}\")\n",
    "\n",
    "> HERE YOUR CODE!\n",
    "\n",
    "print(f\"🚀 결측치 처리 후 :\\n {df.isnull().sum()}\")\n",
    "print(f\"Shape of Data Frame : {df.shape}\")\n",
    "```\n",
    "\n",
    "검색 힌트 : pd.dropna(), pd.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2-2 Scaling 하기  \n",
    "모델의 안정적인 학습을 위해서는 `데이터의 단위를 통일` 시켜주는 것이 좋습니다.  \n",
    "이유는 다음과 같아요!\n",
    "    \n",
    "> 1. Feature간의 상대적 중요도가 더 잘 드러납니다.  \n",
    "> 2. 이상치의 영향력이 감소합니다.  \n",
    "> 3. 연산 효율이 좋아집니다.  \n",
    "    \n",
    "조금 더 직관적인 설명을 드려볼게요.  \n",
    "우리가 만약 주택의 가격을 예측하는 업무를 맡았다고 해볼게요!  \n",
    "주택의 가격을 결정하는 Feature들로 __\"방 개수\", \"주택 평수\"__ 를 설정했다고 해봅시다.  \n",
    "  \n",
    "근데 생각해보면 **방 개수**는 해봐야 1~5개 정도로, **주택 평수**는 1 ~ 100까지 뭐 다양하겠죠?  \n",
    "**즉, 다시 말해 두 데이터간의 범위에 있어서 차이가 발생합니다.**  \n",
    "   \n",
    "그럼, 머신러닝이 이를 학습할 때 어떤 문제가 발생할까요?  \n",
    "  \n",
    "> 🤖: 어... 얘는... 변동폭이 크니까... 중요한가,,,? 얘는... 변동폭이 그리 안 크니까 안 중요한 거겠지,,,?\n",
    "  \n",
    "이런 식으로 오해할 수 있어요. 그러기 때문에, 일반적으로 딥러닝이나 Tree 모델을 제외한 나머지 모델로 학습을 시킬 때는 꼭 Scaling을 진행해주는 것이 좋습니다.  \n",
    "  \n",
    "### 문제\n",
    "`sklearn`의 `StandardScaler`를 이용하여 `X_train`과 `X_val`을 Scaling 해주세요.  \n",
    "\n",
    "단, X_train엔 `fit_transform()`을, X_val엔 `transform()` 메소드를 적용해서 Scaling 해주세요!  \n",
    "  \n",
    "그리고 왜 학습데이터엔 `fit_transform()`을 사용해도 되지만, 검증용이나 테스트 데이터엔 `transform()`만을 이용해야 하는지 적어주세요!\n",
    "  \n",
    "<br>\n",
    "\n",
    "Base Line  \n",
    "```python\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "scaler = '''HERE YOUR CODE!'''\n",
    "\n",
    "scaled_X_train = '''HERE YOUR CODE!'''\n",
    "scaled_X_val = '''HERE YOUR CODE!'''\n",
    "\n",
    "scaled_X_train_check = scaled_X_train.reshape(30, -1)\n",
    "print(f\"Scaling전 데이터의 최대, 최소, 평균, std: {X_train['mean texture'].max(), X_train['mean texture'].min(),  X_train['mean texture'].mean(),  X_train['mean texture'].std()}\")\n",
    "print(f\"Scaling후 데이터의 최대, 최소, 평균, std: {scaled_X_train_check[0].max(), scaled_X_train_check[0].min(), scaled_X_train_check[0].mean(), scaled_X_train_check[0].std()}\")\n",
    "```\n",
    "  \n",
    "<br>\n",
    "\n",
    "검색 힌트 : fit_transform()과 transform()차이, sklearn Standard Scaler, sklearn Scaler 종류\n",
    "  \n",
    "_예시_  \n",
    "![](./2-2answer.png)\n",
    "\n",
    "<br>\n",
    "\n",
    "### ❗ 심화학습 ❗   \n",
    "오잉? 트리모델은 왜 Scaling이 안 필요할까요? 그 작동방식을 한번 확인해보고, 왜 안 필요한지 WIL에 적어주세요! (어떤 형태로든 적어주시면 됩니다. md파일에 그대로 적어주셔도 되고, 블로그에 적어주셔도 되고..) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2-3 학습시키기\n",
    "이제 우리가 전처리한 데이터를 학습시키는 일만 남았습니다.  \n",
    "데이터를 학습할 모델을 고르는 것도 사실 중요한 일 중 하나지만, 일단 저희는 Tree 모델 중에서 가~~~~장 기본이 되는 `DecisionTree`와 `Random Foreset`를 사용해서 성능을 비교해볼게요!  \n",
    "  \n",
    "이번 문제는 그냥 간단하게, `아~ 이런 이런 함수를 써서 학습시키고 예측하는구나~` 정도로만 알고 넘어가셔도 좋을 것같습니다.  \n",
    "  \n",
    "sklearn의 `DecisionTreeClassifier`로 `scaled_X_train`과 `y_train`을 이용해서 학습을 진행해주세요!  \n",
    "단, `DecisionTreeClassifier`의 `random_state`는 42로 고정시켜주세요.\n",
    "\n",
    "<br>\n",
    "\n",
    "**Base Line**\n",
    "```python\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "classifier = '''HERE YOUR CODE!!'''\n",
    "\n",
    "classifier.'''HERE YOUR CODE!!'''\n",
    "\n",
    "print(\"🤖Training is Done!\")\n",
    "```  \n",
    "\n",
    "<br>\n",
    "\n",
    "검색 힌트: sklearn DecisionTree, sklearn 모델 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2-4 예측하기\n",
    "2-3에서 모델을 우리 데이터에 맞게 학습시켰습니다. 이제 그럼 이 학습된 모델이 실전에서 잘 작동할 수 있는지 확인해봐야겠죠?  \n",
    "학습된 모델을 기반으로 데이터를 넣어 prediction을 구할 수 있습니다.  \n",
    "  \n",
    "2-4에서 학습시킨 모델로 `scaled_X_val`을 예측해주세요!  \n",
    "그리고 모델의 정확도(Accuracy)가 얼마나 되는지, `sklearn`의 `accuracy_score`를 통해 계산해주세요!  \n",
    "\n",
    "<br>\n",
    "\n",
    "**Base Line**\n",
    "```python\n",
    "from sklearn.metrics import '''HERE YOUR CODE!!'''\n",
    "\n",
    "predictions = classifier.'''HERE YOUR CODE!!'''\n",
    "accuracy = '''HERE YOUR CODE!!'''\n",
    "\n",
    "print(f\"Model Accuracy: {accuracy}\")\n",
    "```\n",
    "\n",
    "<br>\n",
    "\n",
    "검색 힌트: sklearn 모델 predict, sklearn 정확도 계산  \n",
    "  \n",
    "_예시_  \n",
    "![](./2-4answer.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2-5 다른 모델도 써보기\n",
    "우리는 `DecisionTree`알고리즘을 통해 94% 라는 높은 정확도를 얻어냈습니다.  \n",
    "그럼 Ensemble 모델의 원조할머니급인 `Random Forest`의 성능도 한번 확인해볼까요?  \n",
    "  \n",
    "랜덤포레스트로 학습과 예측, 정확도 계산까지의 코드를 완성해주세요!  \n",
    "단, `RandomForestClassifier`의 random_state는 42로 고정해주세요.\n",
    "\n",
    "<br>\n",
    "\n",
    "```python\n",
    "from sklearn.ensemble import '''HERE YOUR CODE!!'''\n",
    "\n",
    "rf_clf = '''HERE YOUR CODE!!'''\n",
    "rf_clf.'''HERE YOUR CODE!!'''\n",
    "rf_prediction = rf_clf.'''HERE YOUR CODE!!'''\n",
    "\n",
    "rf_acc = '''HERE YOUR CODE!!'''\n",
    "print(f\"Random Forest Model Accuracy: {rf_acc}\")\n",
    "```\n",
    "\n",
    "<br>\n",
    "\n",
    "검색 힌트: sklearn Random Forest\n",
    "  \n",
    "_예시_  \n",
    "![](./2-5answer.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 심화 학습\n",
    "우리는 방금 Decision Tree와 Random Forest의 결과를 비교해봤습니다. 분명 같은 데이터로 두 모델을 학습시켰는데, Random Forest의 정확도가 조금 더 높게 나왔습니다.  \n",
    "**왜 그 럴 까 요?**  \n",
    "Random Forest는 이름에서도 느껴졌듯이, Tree가 여러개 모인 모델입니다.  \n",
    "하나보단 둘이 더 낫고, 셋보단 넷, 넷보단 여러명이 더 나을 때가 있죠. 우리가 함께 모여 팀프로젝트를 하는 이유가 바로 그거구요.  \n",
    "  \n",
    "왜 Random Forest가 Decision Tree보다 더 나은 성능을 보이는지 공부한 결과를 블로그에 정리하신 뒤, 해당 링크를 `@자기혁명왕`에게 보내주세요!  \n",
    "  \n",
    "힌트는 **`Ensemble`** 입니다. 딥러닝에서도 쓰이는 아주 중요한 개념이니, 심화학습이긴 하지만 한번 쯤은 쓱-- 공부라도 하시는 걸 추천드려용 ㅎㅎ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5주차 종료 \n",
    "머신러닝의 가장 일반적인 흐름을 살펴봤습니다. 어떤가요? 생각보다 코드들이 막 그렇게 복잡하지는 않죠?  \n",
    "맞습니다. 사실 `pytorch`나 `tensorflow`와 같은 딥러닝에 특화된 프레임워크가 아닌 `sklearn`은 그렇게 복잡한 코드를 요구하지는 않습니다.  \n",
    "  \n",
    "때문에, 코드적 스킬보다는 그 코드가 의미하는 것, 그리고 개념이 더 중요하다고 할 수 있죠.  \n",
    "  \n",
    "사실 성능도 코드를 어떻게 잘 지지고 볶았냐에서 갈린다고 하기 보다는 데이터 전처리를 얼마나 알맞게 잘 했냐, 어떤 아이디어를 적용시켰냐! 가 사실은 성능에 있어서 더 큰 영향을 주더라구용  \n",
    "  \n",
    "위의 과정에서 나온 `Scaling`, `fit`과 `fit_transform()`의 차이, `결측치 처리 방법` 모두 머신러닝을 할 때 성능을 가를 수 있는 중요한 요소들입니다.  \n",
    "시간 되실 때, 꼭 한번쯤은 복습하시는 걸 추천드려요 ㅎㅎ\n",
    "  \n",
    "## 숙제 \n",
    "시험기간인 만큼, 큰 부담은 최대한 안 드리려고 합니다.  \n",
    "여러분이 위의 과정을 하시면서 배운 것들을 블로그에 정리한 뒤, md 파일에 블로그 링크를 함께 달아주세요!  \n",
    "  \n",
    "궁금하신 게 생기시면 언제든지 편하게 질문주세요 ㅎㅎ 그럼 다음에 봐요! \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "768016c7aa7eaabec9016402577e4cabb606e332b3187c608d53990dc1c3c37f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
